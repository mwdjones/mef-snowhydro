bison = lterdatasampler::knz_bison
head(bison)
summary(duplicated(bison$animal_code))
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)
library(tidyverse)
library(ggplot2)
library(janitor)
library(magrittr)
library(cowplot)
#Download sample data
#install.packages('remotes')
remotes::install_github("lter/lterdatasampler")
bison = lterdatasampler::knz_bison
head(bison)
summary(duplicated(bison$animal_code))
#Calculate the age of each bison
bison %<>%
mutate(animal_age = rec_year - animal_yob) %<>%
mutate(animal_sex = as.factor(bison$animal_sex))
head(bison)
ggplot(data = bison, aes(x = animal_age, y = animal_weight, color = animal_sex)) +
geom_jitter()
ggplot(data = bison, aes(x = animal_age, y = animal_weight, color = animal_sex)) +
geom_jitter() +
theme_cowplot(12)
ggplot(data = bison, aes(x = animal_age, y = animal_weight, color = animal_sex)) +
geom_jitter() +
theme_cowplot(10)
ggplot(data = bison, aes(x = animal_age, y = animal_weight, color = animal_sex)) +
geom_jitter() +
theme_cowplot(12)
ggplot(data = bison, aes(x = animal_age, y = animal_weight, color = animal_sex)) +
geom_jitter() +
theme_minimal_grid(12)
install.packages('extrafont')
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)
library(tidyverse)
library(ggplot2)
library(janitor)
library(magrittr)
library(cowplot)
library(extrafont)
#Download sample data
#install.packages('remotes')
remotes::install_github("lter/lterdatasampler")
font_import()
fonts()
fonttable()
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(ggplot2)
library(janitor)
library(magrittr)
library(cowplot)
library(extrafont)
data <- read.csv(file = "C:\Users\marie\Desktop\Art\timeline")
data <- read.csv(file = "C:/Users/marie/Desktop/Art/timeline.csv")
data <- read.csv(file = "C:/Users/marie/Desktop/Art/timeline.xlsx")
data <- read.csv(file = "C:/Users/marie/Desktop/Art/timeline.xlsx", header = 1)
data <- read.csv(file = "C:/Users/marie/Desktop/Art/timeline.xlsx", header = T)
data <- read.csv(file = "C:/Users/marie/Desktop/Art/timeline.csv", header = T)
data.head()
data.describe()```
#Load data
data <- read.csv(file = "C:/Users/marie/Desktop/Art/timeline.csv", header = T)
data.describe()
describe(data)
data[:5]
data
install.packages('streamgraph')
devtools::install_github("hrbrmstr/streamgraph")
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(ggplot2)
library(janitor)
library(magrittr)
library(cowplot)
library(extrafont)
library(streamgraph)
library(extrafont)
library(extrafont)
data
plot.stream <- function(
x, y,
order.method = "as.is", frac.rand=0.1, spar=0.2,
center=TRUE,
ylab="", xlab="",
border = NULL, lwd=1,
col=rainbow(length(y[1,])),
ylim=NULL,
...
){
if(sum(y < 0) > 0) error("y cannot contain negative numbers")
if(is.null(border)) border <- par("fg")
border <- as.vector(matrix(border, nrow=ncol(y), ncol=1))
col <- as.vector(matrix(col, nrow=ncol(y), ncol=1))
lwd <- as.vector(matrix(lwd, nrow=ncol(y), ncol=1))
if(order.method == "max") {
ord <- order(apply(y, 2, which.max))
y <- y[, ord]
col <- col[ord]
border <- border[ord]
}
if(order.method == "first") {
ord <- order(apply(y, 2, function(x) min(which(x>0))))
y <- y[, ord]
col <- col[ord]
border <- border[ord]
}
bottom.old <- x*0
top.old <- x*0
polys <- vector(mode="list", ncol(y))
for(i in seq(polys)){
if(i %% 2 == 1){ #if odd
top.new <- top.old + y[,i]
polys[[i]] <- list(x=c(x, rev(x)), y=c(top.old, rev(top.new)))
top.old <- top.new
}
if(i %% 2 == 0){ #if even
bottom.new <- bottom.old - y[,i]
polys[[i]] <- list(x=c(x, rev(x)), y=c(bottom.old, rev(bottom.new)))
bottom.old <- bottom.new
}
}
ylim.tmp <- range(sapply(polys, function(x) range(x$y, na.rm=TRUE)), na.rm=TRUE)
outer.lims <- sapply(polys, function(r) rev(r$y[(length(r$y)/2+1):length(r$y)]))
mid <- apply(outer.lims, 1, function(r) mean(c(max(r, na.rm=TRUE), min(r, na.rm=TRUE)), na.rm=TRUE))
#center and wiggle
if(center) {
g0 <- -mid + runif(length(x), min=frac.rand*ylim.tmp[1], max=frac.rand*ylim.tmp[2])
} else {
g0 <- runif(length(x), min=frac.rand*ylim.tmp[1], max=frac.rand*ylim.tmp[2])
}
fit <- smooth.spline(g0 ~ x, spar=spar)
for(i in seq(polys)){
polys[[i]]$y <- polys[[i]]$y + c(fit$y, rev(fit$y))
}
if(is.null(ylim)) ylim <- range(sapply(polys, function(x) range(x$y, na.rm=TRUE)), na.rm=TRUE)
plot(x,y[,1], ylab=ylab, xlab=xlab, ylim=ylim, t="n", ...)
for(i in seq(polys)){
polygon(polys[[i]], border=border[i], col=col[i], lwd=lwd[i])
}
}
install.packages("remotes")
remotes::install_github("davidsjoberg/ggstream")
install.packages("remotes")
remotes::install_github("davidsjoberg/ggstream")
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
knitr::opts_chunk$set(echo = TRUE)
library(ggstream)
remotes::install_github("davidsjoberg/ggstream")
knitr::opts_chunk$set(echo = TRUE)
beerprod = scan("./data/beerprod.dat")
beerprod =ts(beerprod, freq = 4)
decompdeer = decompose(beerprod, type = 'additive')
decompdeer = decompose(beerprod, type = 'additive')
plot(decompbeer)
decompbeer = decompose(beerprod, type = 'additive')
plot(decompbeer)
decompbeermult = decomp(beerprod, type = 'multiplicative')
decompbeermult = decompose(beerprod, type = 'multiplicative')
plor(decompbeermult)
decompbeermult = decompose(beerprod, type = 'multiplicative')
plot(decompbeermult)
beerprod = scan("beerprod.dat")
trendpattern = filter (beerprod, filter = c(1/8, 1/4, 1/4, 1/4, 1/8), sides=2)
plot (beerprod, type= "b", main = "moving average annual trend")
lines (trendpattern)
trendpattern = filter (beerprod, filter = c(1/8, 1/4, 1/4, 1/4, 1/8), sides=2)
plot (beerprod, type= "b", main = "moving average annual trend")
lines (trendpattern, 'r')
trendpattern = filter (beerprod, filter = c(1/8, 1/4, 1/4, 1/4, 1/8), sides=2)
plot (beerprod, type= "b", main = "moving average annual trend")
lines (trendpattern, 'red')
trendpattern = filter (beerprod, filter = c(1/8, 1/4, 1/4, 1/4, 1/8), sides=2)
plot (beerprod, type= "b", main = "moving average annual trend")
lines (trendpattern)
knitr::opts_chunk$set(echo = TRUE)
beerprod = scan("./data/beerprod.dat")
beerprod =ts(beerprod, freq = 4)
#detrend
x = diff(beerprod)
#FFT function - n in the sqrt
I = abs(fft(x)/sqrt(72))^2
#Pick out the first half of the frequencies - scale slightly
P = (4/36)*I[1:36]
#Crete harmonic frequencies
freq = (0:36)/72
plot(freq,P,type="l")
#detrend
x = diff(beerprod)
#FFT function - n in the sqrt
I = abs(fft(x)/sqrt(72))^2
#Pick out the first half of the frequencies - scale slightly
P = (4/36)*I[1:37]
#Crete harmonic frequencies
freq = (0:36)/72
plot(freq, P, type="l")
knitr::opts_chunk$set(echo = TRUE)
###Install packages
#install.packages("astsa") # nolint
library(astsa)
x=ts(scan("./data/econpredictor.dat"))
x=ts(scan("./data/econpredictor_1.dat"))
y=ts(scan("./data/econmeasure_0.dat"))
plot.ts(x,y,xy.lines=F,xy.labels=F)
regmodel=lm(y~x)
summary(regmodel)
acf2(residuals(regmodel))
ar1res = sarima (residuals(regmodel), 1,0,0, no.constant=T) #AR(1)
xl = ts.intersect(x, lag(x,-1)) # Create matrix with x and lag 1 x as elements
xnew=xl[,1] - 0.6488*xl[,2] # Create x variable for adjustment regression
yl = ts.intersect(y,lag(y,-1)) # Create matrix with y and lag 1 y as elements
ynew=yl[,1]-0.6488*yl[,2] # Create y variable for adjustment regression
adjustreg = lm(ynew~xnew) # Adjustment regression
summary(adjustreg)
acf2(residuals(adjustreg))
install.packages("orcutt")
library(orcutt)
cochrane.orcutt(regmodel)
summary(cochrane.orcutt(regmodel))
library(astsa)
soi= scan("soi.dat")
soi= scan("./data/soi.dat")
rec = scan("./data/recruit.dat")
soi=ts (soi)
rec = ts(rec)
ccfvalues =ccf (soi, rec)
ccfvalues
lag2.plot (soi, rec, 10)
alldata=ts.intersect(rec,reclag1=lag(rec,-1), reclag2=lag(rec,-2), soilag5 = lag(soi,-5),
soilag6=lag(soi,-6), soilag7=lag(soi,-7), soilag8=lag(soi,-8), soilag9=lag(soi,-9),
soilag10=lag(soi,-10))
tryit = lm(rec~soilag5+soilag6+soilag7+soilag8+soilag9+soilag10, data = alldata)
summary (tryit)
acf2(residuals(tryit))
tryit2 = lm(rec~reclag1+reclag2+soilag5+soilag6+soilag7+soilag8+soilag9+soilag10,
data = alldata)
summary (tryit2)
acf2(residuals(tryit2))
tryit3 = lm(rec~reclag1+reclag2+ soilag5+soilag6, data = alldata)
summary (tryit3)
acf2(residuals(tryit3))
knitr::opts_chunk$set(echo = TRUE)
#install.packages("astsa")
library(astsa)
library(dplyr)
library(tidyverse)
### Import Snow Data
s2data = read.csv("D:/1_DesktopBackup/Feng Research/0_MEF Snow Hydology/mef-snowhydro/Data and Codes/Cleaned Data/01_cleanedsnowdataS2.csv",
header = TRUE,
sep = ",",
#col.names = c("time", "northing", "easting", "zones", "stakes",
#              "aspect", "slope", "watershed")
)
s2data = na.omit(s2data)
s6data = read.csv("D:/1_DesktopBackup/Feng Research/0_MEF Snow Hydology/mef-snowhydro/Data and Codes/Cleaned Data/01_cleanedsnowdataS6.csv",
header = TRUE,
sep = ",",
#col.names = c("time", "northing", "easting", "zones", "stakes",
#              "aspect", "slope", "watershed")
)
s6data = na.omit(s6data)
View(s2data)
#Check data
head(s2data)
#Groupby date and zone -- eliminate stake names
s2data_grouped  = s2data %>%
group_by(time, zones) %>%
summarize(mean_depth = mean(depths))
head(s2data_grouped)
s6data_grouped  = s6data %>%
group_by(time, zones) %>%
summarize(mean_depth = mean(depths))
head(s6data_grouped)
#Set time series
s2_depths = ts(s2data_grouped$mean_depth)
s2_times = ts(s2data_grouped$time)
s2_zones = ts(s2data_grouped$zones)
s6_depths = ts(s6data_grouped$mean_depth)
s6_times = ts(s6data_grouped$time)
s6_zones = ts(s6data_grouped$zones)
#Run S2 Repeated Measures ANOVA
Y = s2data$depths
aov.p = aov(Y ~ (factor(zones)*factor(time))+Error(factor(stakes)), s2data)
summary(aov.p)
#Results -- Betweens are not significant, as we expected. There is no sig difference between the zones. Within a zone, however, there is a significant trend with time (as we would hope) and there is a significant interaction with zone and time, so even though the overall means might be different there is a slight difference in slopes.
#Run S2 Repeated Measures ANOVA
Y = s6data$depths
aov.p = aov(Y ~ (factor(zones)*factor(time))+Error(factor(stakes)), s6data)
summary(aov.p)
#Results - Between the zones there is a significant difference (yay!) and within the zones there is a signifcant relationship with time, expected, and a slight difference in slopes, although not as significant as the S2 data.
knitr::opts_chunk$set(echo = TRUE)
#install.packages("astsa")
library(astsa)
library(dplyr)
library(tidyverse)
### Import Snow Data
s2data = read.csv("D:/1_DesktopBackup/Feng Research/0_MEF Snow Hydology/mef-snowhydro/Data and Codes/Cleaned Data/01_cleanedsnowdataS2.csv",
header = TRUE,
sep = ",",
#col.names = c("time", "northing", "easting", "zones", "stakes",
#              "aspect", "slope", "watershed")
)
### Import Snow Data
s2data = read.csv("D:/1_DesktopBackup/Feng Research/0_MEF Snow Hydology/mef-snowhydro/Data and Codes/Cleaned Data/01_cleanedsnowdataS2.csv",
header = TRUE,
sep = ",",
#col.names = c("time", "northing", "easting", "zones", "stakes",
#              "aspect", "slope", "watershed")
)
setwd("C:/Users/marie/Desktop/mef-snowhydro")
#setwd("C:/Users/marie/Desktop/mef-snowhydro")
### Import Snow Data
s2data = read.csv("D:/1_DesktopBackup/Feng Research/0_MEF Snow Hydology/mef-snowhydro/Data and Codes/Cleaned Data/01_cleanedsnowdataS2.csv",
header = TRUE,
sep = ",",
#col.names = c("time", "northing", "easting", "zones", "stakes",
#              "aspect", "slope", "watershed")
)
#setwd("C:/Users/marie/Desktop/mef-snowhydro")
### Import Snow Data
s2data = read.csv("./Data and Codes/Cleaned Data/01_cleanedsnowdataS2.csv",
header = TRUE,
sep = ",",
#col.names = c("time", "northing", "easting", "zones", "stakes",
#              "aspect", "slope", "watershed")
)
#setwd("C:/Users/marie/Desktop/mef-snowhydro")
### Import Snow Data
s2data = read.csv("/Data and Codes/Cleaned Data/01_cleanedsnowdataS2.csv",
header = TRUE,
sep = ",",
#col.names = c("time", "northing", "easting", "zones", "stakes",
#              "aspect", "slope", "watershed")
)
#setwd("C:/Users/marie/Desktop/mef-snowhydro")
### Import Snow Data
s2data = read.csv("/Data and Codes/Cleaned Data/01_cleanedsnowdataS2.csv",
header = TRUE,
sep = ",",
#col.names = c("time", "northing", "easting", "zones", "stakes",
#              "aspect", "slope", "watershed")
)
#setwd("C:/Users/marie/Desktop/mef-snowhydro")
### Import Snow Data
s2data = read.csv("/Data and Codes/Cleaned Data/01_cleanedsnowdataS2.csv",
header = TRUE,
sep = ",",
#col.names = c("time", "northing", "easting", "zones", "stakes",
#              "aspect", "slope", "watershed")
)
#setwd("C:/Users/marie/Desktop/mef-snowhydro")
### Import Snow Data
s2data = read.csv("Data and Codes/Cleaned Data/01_cleanedsnowdataS2.csv",
header = TRUE,
sep = ",",
#col.names = c("time", "northing", "easting", "zones", "stakes",
#              "aspect", "slope", "watershed")
)
#setwd("C:/Users/marie/Desktop/mef-snowhydro")
### Import Snow Data
s2data = read.csv("/Data and Codes/Cleaned Data/01_cleanedsnowdataS2.csv",
header = TRUE,
sep = ",",
#col.names = c("time", "northing", "easting", "zones", "stakes",
#              "aspect", "slope", "watershed")
)
#install.packages("astsa")
library(astsa)
library(dplyr)
library(tidyverse)
#setwd("C:/Users/marie/Desktop/mef-snowhydro")
### Import Snow Data
s2data = read.csv("/Data and Codes/Cleaned Data/01_cleanedsnowdataS2.csv",
header = TRUE,
sep = ",",
#col.names = c("time", "northing", "easting", "zones", "stakes",
#              "aspect", "slope", "watershed")
)
knitr::opts_chunk$set(echo = TRUE)
#install.packages("astsa")
library(astsa)
library(dplyr)
library(tidyverse)
#setwd("C:/Users/marie/Desktop/mef-snowhydro")
### Import Snow Data
s2data = read.csv("/Data and Codes/Cleaned Data/01_cleanedsnowdataS2.csv",
header = TRUE,
sep = ",",
#col.names = c("time", "northing", "easting", "zones", "stakes",
#              "aspect", "slope", "watershed")
)
knitr::opts_chunk$set(echo = TRUE)
#install.packages("astsa")
library(astsa)
library(dplyr)
library(tidyverse)
#setwd("C:/Users/marie/Desktop/mef-snowhydro")
### Import Snow Data
s2data = read.csv("/Data and Codes/Cleaned Data/01_cleanedsnowdataS2.csv",
header = TRUE,
sep = ",",
#col.names = c("time", "northing", "easting", "zones", "stakes",
#              "aspect", "slope", "watershed")
)
#setwd("C:/Users/marie/Desktop/mef-snowhydro")
### Import Snow Data
s2data = read.csv("./Data and Codes/Cleaned Data/01_cleanedsnowdataS2.csv",
header = TRUE,
sep = ",",
#col.names = c("time", "northing", "easting", "zones", "stakes",
#              "aspect", "slope", "watershed")
)
setwd("C:/Users/marie/Desktop/mef-snowhydro")
### Import Snow Data
s2data = read.csv("./Data and Codes/Cleaned Data/01_cleanedsnowdataS2.csv",
header = TRUE,
sep = ",",
#col.names = c("time", "northing", "easting", "zones", "stakes",
#              "aspect", "slope", "watershed")
)
s2data = na.omit(s2data)
s6data = read.csv("./Data and Codes/Cleaned Data/01_cleanedsnowdataS6.csv",
header = TRUE,
sep = ",",
#col.names = c("time", "northing", "easting", "zones", "stakes",
#              "aspect", "slope", "watershed")
)
s6data = na.omit(s6data)
#Check data
head(s2data)
#Check data
foot(s2data)
#Check data
head(s2data)
View(s2data)
View(s2data)
#Groupby date and zone -- eliminate stake names
s2data_grouped  = s2data %>%
group_by(time, zones) %>%
summarize(mean_depth = mean(depths))
head(s2data_grouped)
s6data_grouped  = s6data %>%
group_by(time, zones) %>%
summarize(mean_depth = mean(depths))
head(s6data_grouped)
#Set time series
s2_depths = ts(s2data_grouped$mean_depth)
s2_times = ts(s2data_grouped$time)
s2_zones = ts(s2data_grouped$zones)
s6_depths = ts(s6data_grouped$mean_depth)
s6_times = ts(s6data_grouped$time)
s6_zones = ts(s6data_grouped$zones)
#Run S2 Repeated Measures ANOVA
Y = s2data$depths
aov.p = aov(Y ~ (factor(zones)*factor(time))+Error(factor(stakes)), s2data)
summary(aov.p)
#Results -- Betweens are not significant, as we expected. There is no sig difference between the zones. Within a zone, however, there is a significant trend with time (as we would hope) and there is a significant interaction with zone and time, so even though the overall means might be different there is a slight difference in slopes.
#Run S2 Repeated Measures ANOVA
Y = s6data$depths
aov.p = aov(Y ~ (factor(zones)*factor(time))+Error(factor(stakes)), s6data)
summary(aov.p)
#Results - Between the zones there is a significant difference (yay!) and within the zones there is a signifcant relationship with time, expected, and a slight difference in slopes, although not as significant as the S2 data.
s2_bog = s2data %>%
filter(zone == 'Bog')
s2_bog = s2data %>%
filter(zones == 'Bog')
s2bog = s2data %>%
filter(zones == 'Bog')
s6bog = s6data %>%
filter(zones == 'Bog')
s2lagg = s2data %>%
filter(zones == 'Lagg')
s6lagg = s6data %>%
filter(zones == 'Lagg')
s2upland = s2data %>%
filter(zones == 'Upland')
s6upland = s6data %>%
filter(zones == 'Upland')
bog = alldata %>%
filter(zones == 'Bog')
alldata = rbind(s2data, s6data)
bog = alldata %>%
filter(zones == 'Bog')
lagg = alldata %>%
filter(zones == 'Lagg')
upland = alldata %>%
filter(zones == 'Upland')
alldata
alldata = rbind(s2data, s6data)
bog = alldata %>%
filter(zones == 'Bog')
lagg = alldata %>%
filter(zones == 'Lagg')
upland = alldata %>%
filter(zones == 'Upland')
#Run Upland Repeated Measures ANOVA
Y = upland$depths
aov.p = aov(Y ~ (factor(watershed)*factor(time))+Error(factor(stakes)), upland)
summary(aov.p)
#Run Lagg Repeated Measures ANOVA
Y = lagg$depths
aov.p = aov(Y ~ (factor(watershed)*factor(time))+Error(factor(stakes)), lagg)
summary(aov.p)
#Run Bog Repeated Measures ANOVA
Y = bog$depths
aov.p = aov(Y ~ (factor(watershed)*factor(time))+Error(factor(stakes)), bog)
summary(aov.p)
